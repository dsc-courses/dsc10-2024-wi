{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Hypothesis Testing and Permutation Testing\n",
    "\n",
    "## Due Thursday, March 7th at 11:59PM\n",
    "\n",
    "Welcome to Homework 6, the last homework of the quarter! This homework covers hypothesis testing ([CIT 11](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)) and permutation testing ([CIT 12](https://inferentialthinking.com/chapters/12/Comparing_Two_Samples.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or Ed. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "def show_clt_slides():\n",
    "    src = 'https://docs.google.com/presentation/d/e/2PACX-1vTcJd3U1H1KoXqBFcWGKFUPjZbeW4oiNZZLCFY8jqvSDsl4L1rRTg7980nPs1TGCAecYKUZxH5MZIBh/embed?start=false&loop=false&delayms=3000&rm=minimal'\n",
    "    width = 700\n",
    "    height = 370\n",
    "    display(IFrame(src, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Secret Smiski üßç\n",
    "\n",
    "<img src='images/smiskis.png' width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smiskis are tiny glow-in-the-dark collectible figurines. Each Smiski is packaged in an identical box so that you don't know which Smiski you have when you pick up a box. Due to this packaging, it isn't easy to get a specific Smiski, but it's even rarer to get a special type of Smiski called the *secret* Smiski. Although no one knows the exact probability of obtaining a secret Smiski, you [read online](https://www.reddit.com/r/smiskis/comments/15myvll/how_rare_are_secret_smiskis_really/) that chance of obtaining a secret Smiski is $\\frac{1}{144}$. \n",
    "\n",
    "Many of the DSC 10 tutors are avid Smiski collectors and have collectively bought 903 Smiskis over the past few years. Out of all the Smiskis they collected, they got 10 secret Smiskis. Due to this outcome, the tutors suspect the probability of getting a secret Smiski should be higher than $\\frac{1}{144}$.\n",
    "\n",
    "To test this, they decide to run a hypothesis test with the following hypotheses:\n",
    "\n",
    "**Null Hypothesis**: The probability of obtaining a secret Smiski is $\\frac{1}{144}$. \n",
    "\n",
    "**Alternative Hypothesis**: The probability of obtaining a secret Smiski is greater than $\\frac{1}{144}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Complete the implementation of the function `one_simulation`, which has no arguments. It should randomly generate 903 Smiskis under the assumptions of the null hypothesis and return the **proportion** of Smiskis that are secret Smiskis. \n",
    "\n",
    "***Hint:*** Use `np.random.multinomial`. You don't need a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulation():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** The test statistic for our hypothesis test will be the difference between the proportion of secret Smiskis obtained in a given sample of 903 Smiskis and the expected proportion of secret Smiskis.\n",
    "\n",
    "$$\\text{test statistic} = \\text{proportion of secret Smiskis in sample} - \\frac{1}{144}$$\n",
    "\n",
    "Let's conduct 10,000 simulations. Create an array named `proportion_diffs` containing 10,000 simulated values of the test statistic described above. Utilize the function created in the previous question to perform this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_diffs = ...\n",
    "\n",
    "# Visualize with a histogram. Don't change anything below.\n",
    "bpd.DataFrame().assign(proportion_differences=proportion_diffs).plot(kind='hist', bins=15, density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=(10/903 - 1/144), color='black', linewidth=4, label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Calculate the p-value for this hypothesis test, and assign the result to `secret_smiski_p`.\n",
    "\n",
    "***Hint:*** Do large values of our test statistic favor the alternative hypothesis, or do small values of our test statistic favor the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_smiski_p = ...\n",
    "secret_smiski_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `secret_smiski_conclusion`, corresponding to the best conclusion.\n",
    "\n",
    "   1. We reject the null hypothesis. There is not enough evidence to draw a conclusion about whether the data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_smiski_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** In this question, we chose as our test statistic the proportion of secret Smiskis obtained minus $\\frac{1}{144}$. But this is not the only statistic we could have chosen; there are many that could have worked here. \n",
    "\n",
    "From the options below, choose the test statistics that would **not** have worked for this hypothesis test, and assign the variable `bad_choices` to a list of your choices.\n",
    "\n",
    "1. The number of secret Smiskis obtained out of 903 Smiskis.\n",
    "1. The absolute difference between 10 and the number of secret Smiskis obtained.\n",
    "1. The absolute difference between $\\frac{1}{144}$ and the proportion of secret Smiskis obtained.\n",
    "1. $\\frac{1}{144}$ minus the proportion of secret Smiskis obtained.\n",
    "\n",
    "***Hint:*** Our goal is to find a test statistic that will help us determine whether we got secret Smiskis **more** often than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_choices = ...\n",
    "bad_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <span> Mystery Box</span> üéÅ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/subway_surfers.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subway Surfers is an \"endless runner\" mobile game where the player controls a character that continually runs forward along a subway track. The player tries to dodge obstacles and collect rewards along the way, all while avoiding train collisions and being caught by the subway inspector. One of the rewards is a Mystery Box which contains one of several possible prizes.\n",
    "\n",
    "<img src='images/mystery_box.png' width='600'>\n",
    "\n",
    "There are four types of prizes in a Mystery Box: `'Jackpot'`, `'Rare'`, `'Special'`, and `'Common'`. The most valuable is the `'Jackpot'` ü§© but it's also the most rare. Unfortunately, there is no publicly available information on the exact probabilities of getting any of the four types of prizes in a Mystery Box. However, our DSC 10 tutor Jack plays Subway Surfers a lot, and based on his experience with the game, he proposes the following probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type | Jack's Estimated Probability|\n",
    "| --- | --- |\n",
    "| Jackpot | $0.02$ |\n",
    "| Rare | $0.10$ |\n",
    "| Special | $0.25$ |\n",
    "| Common | $0.63$ |\n",
    "\n",
    "We'll store this distribution in an array, in the order `'Jackpot'`, `'Rare'`, `'Special'`, and `'Common'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "jack_dist = np.array([0.02, 0.1, 0.25, 0.63])\n",
    "jack_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the validity of Jack's model, you collect data from many Subway Surfers players. You learn that in total, out of 2,902 Mystery Box prizes:\n",
    "- 43 were `'Jackpot'`,\n",
    "- 329 were `'Rare'`,\n",
    "- 667 were `'Special'`, and\n",
    "- the rest were `'Common'`.\n",
    "\n",
    "You then calculate the **empirical** type distribution using the data you collected and store it in an array as well (in the same order as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "empirical_dist = np.array([43, 329, 667, 2902 - (43 + 329 + 667)]) / 2902\n",
    "empirical_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `empirical_dist` is not identical to `jack_dist`, it's still possible that Jack's model is plausible, and that the observed differences are due to random chance. Let's run a hypothesis test to investigate further, using the following hypotheses: \n",
    "\n",
    "**Null Hypothesis**: The types of Mystery Box prizes are drawn randomly from the distribution `jack_dist`.\n",
    "\n",
    "**Alternative Hypothesis**: The types of Mystery Box prizes are _not_ drawn randomly from the distribution `jack_dist`.\n",
    "\n",
    "Note that this hypothesis test involves four proportions ‚Äì one for each of `'Jackpot'`, `'Rare'`, `'Special'`, and `'Common'`.\n",
    "\n",
    "**Question 2.1.**  Which of the following is **not** a reasonable choice of test statistic for this hypothesis test? Assign 1, 2, or 3 to the variable `unreasonable_test_statistic`. \n",
    "1. The absolute difference between the sum of the proposed distribution (Jack's expected proportion of types) and the sum of the empirical distribution (actual proportion of types).\n",
    "1. The sum of the absolute difference between the proposed distribution (Jack's expected proportion of types) and the empirical distribution (actual proportion of types).\n",
    "1. Among all four prize types, the largest absolute difference between Jack's expected proportion and the actual proportion of prizes of that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unreasonable_test_statistic = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** We'll use the TVD, i.e. **total variation distance**, as our test statistic. Below, complete the implementation of the function `total_variation_distance`, which takes in two distributions (stored as arrays) as arguments and returns the total variation distance between the two arrays.\n",
    "\n",
    "Then, use the function `total_variation_distance` to determine the TVD between the type distribution proposed by Jack and the empirical type distribution you observed. Assign this TVD to `observed_tvd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(first_distrib, second_distrib):\n",
    "    '''Computes the total variation distance between two distributions.'''\n",
    "    ...\n",
    "\n",
    "observed_tvd = ...\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Now, we'll calculate 5,000 simulated TVDs to see what a typical TVD between the proposed distribution and an empirical distribution would look like if Jack's model were accurate. Since our real-life data includes 2,902 Mystery Box prizes, in each trial of the simulation, we'll:\n",
    "- draw 2,902 Mystery Boxes at random from Jack's proposed distribution, then \n",
    "- calculate the TVD between **Jack's proposed type distribution** and the **empirical type distribution from the simulated sample**. \n",
    "\n",
    "Store these 5,000 simulated TVDs in an array called `simulated_tvds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulated_tvds = ...\n",
    "\n",
    "# Visualize the distribution of TVDs with a histogram\n",
    "bpd.DataFrame().assign(simulated_tvds=simulated_tvds).plot(kind='hist', density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=observed_tvd, color='black', linewidth=4, label='observed TVD')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Now, determine the p-value for our test by finding the proportion of times in our simulation that we saw a TVD greater than or equal to our observed TVD. Assign your result to `subway_surfers_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subway_surfers_p = ...\n",
    "subway_surfers_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `subway_surfers_conclusion`, corresponding to the best conclusion.\n",
    "   \n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. There is not enough evidence to say if the observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_surfers_conclusion = ...\n",
    "subway_surfers_conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Award-Winning Anime üê±‚Äçüë§üèÜ\n",
    "<img src='images/attack-on-titan.jpg' width='1000'>\n",
    "\n",
    "The `animes.csv` dataset from [Kaggle](https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset?resource=download) contains more than 10,000 anime TV series, movies, and OVAs (original video animations). See if your favorite anime is in there!\n",
    "\n",
    "The data contains six columns: `'Name'`, `'English name'`, `'Episodes'`, `'Aired'`, `'Genres'`, `'Score'`. Let's read it in and store it as a DataFrame named `anime`.\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| `'Name'` | The name of the anime in its original language |\n",
    "| `'English name'` | The English name of the anime |\n",
    "| `'Episodes'` | The number of episodes in the anime |\n",
    "| `'Aired'` | The dates when the anime was aired |\n",
    "| `'Genres'` | The genres of the anime, separated by commas |\n",
    "| `'Score'` | The score given to the anime |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = bpd.read_csv('data/animes.csv')\n",
    "anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some rows of the DataFrame preview above, such as the first row for `'Cowboy Bebop'`, include `'Award-Winning'` in the `'Genres'` column. This means the anime won an award, such as the Crunchyroll Anime Award. In 2023, this award was given to  *Cyberpunk: Edgerunners* in case you want to check it out.\n",
    "\n",
    "In this section, we will explore whether the scores for award-winning animes come from the same distribution as non-winning animes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Complete the implementation of the function `label_award`, which takes in a string of genres associated with a single row of `anime` and returns either `'Award-Winning'` or `'No Award'`. \n",
    "\n",
    "Once you've done that, use your function to help you create a new DataFrame named `anime_labeled` that has all the same columns as `anime`, in the same order, with an additional column named `'Award_Status'` that contains whether the anime is award-winning. The `'Award_Status'` column should contain only two distinct values: `'Award-Winning'` and `'No Award'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_award(genres): \n",
    "    ...\n",
    "    \n",
    "anime_labeled = ...\n",
    "anime_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Using the DataFrame `anime_labeled`, calculate the difference between the **mean** `'Score'` of award-winning animes and non-winning animes. Assign your answer to `observed_difference`.\n",
    "\n",
    "$$\\text{observed difference} = \\text{mean award-winning anime score} - \\text{mean non-winning anime score}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** What does the number you obtained for `observed_difference` mean? Assign `interpretation` to 1, 2, 3, or 4, corresponding to the best explanation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our sample, the mean award-winning anime score is higher than the mean non-winning anime score by about 82 percent.\n",
    "1. In our sample, the mean award-winning anime score is higher than the mean non-winning anime score by about 0.82 percent.\n",
    "1. In our sample, the mean award-winning anime score is higher than the mean non-winning anime score by about 0.82 points.\n",
    "1. In our sample, the mean non-winning anime score is higher than the mean award-winning anime score by about 82 percent.\n",
    "1. In our sample, the mean non-winning anime score is higher than the mean award-winning anime score by about 0.82 percent.\n",
    "1. In our sample, the mean non-winning anime score is higher than the mean award-winning anime score by about 0.82 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we want to conduct a **permutation test** to see if it is by chance that the average score for award-winning animes is higher than the average score of non-winning animes in our sample, or if award-winning animes actually have a higher score on average than non-winning animes.\n",
    "\n",
    "- **Null Hypothesis**: The scores of award-winning animes and non-winning animes come from the same distribution.  \n",
    "- **Alternative Hypothesis**: The scores of award-winning animes are higher on average than the scores of non-winning animes.\n",
    "\n",
    "**Question 3.4.** Assign `reduced_df` to a DataFrame with only two columns, `'Award_Status'` and `'Score'`, since these are the only relevant columns in `anime_labeled` for this permutation test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = ...\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Run a permutation test to see if the `observed_difference` is a statistically significant difference. To run this permutation test, simulate 1000 values of the test statistic. For each test statistic, shuffle the `'Award_Status'` column of `reduced_df` and calculate the difference in mean score (award-winning minus non-winning). Store your 1000 differences in the `differences` array. Be sure not to shuffle the `'Score'` column. \n",
    "\n",
    "***Hint:*** It's a good idea to simulate one value of the test statistic before putting everything in a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "differences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.** Compute a p-value for this hypothesis test and assign your answer to `anime_p`. To decide whether to use `<=` or `>=` in the calculation of the p-value, think about whether larger values or smaller values of our test statistic favor the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_p = ...\n",
    "anime_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** Assign the variable `anime_conclusion` to a **list** of all the true statements below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We accept the null hypothesis at the 0.01 significance level.\n",
    "1. We reject the null hypothesis at the 0.01 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.01 significance level.\n",
    "1. We accept the null hypothesis at the 0.05 significance level.\n",
    "1. We reject the null hypothesis at the 0.05 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.05 significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Suppose in this question you had shuffled the `'Score'` column instead and kept the `'Award_Status'` column in the same order. Assign `shuffled_score` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "\n",
    "1. The new p-value from shuffling `'Score'` would be $1 - p$, where $p$ is the old p-value from shuffling `'Award_Status'` (i.e. your answer to Question 3.6).\n",
    "1. We would need to change our null hypothesis in order to shuffle the `'Score'` column. \n",
    "1. There would be no difference in the conclusion of the test if we had shuffled the `'Score'` column instead.\n",
    "1. The `'Score'` column cannot be shuffled because it contains numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Which of the following choices best describes the purpose of shuffling one of the columns in our dataset in a permutation test? Assign `why_shuffle` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "1. Shuffling mitigates noise in our data by generating new permutations of the data.\n",
    "1. Shuffling is a special case of bootstrapping and allows us to produce interval estimates.\n",
    "1. Shuffling allows us to generate new data under the null hypothesis, which we can use in testing our hypothesis.\n",
    "1. Shuffling allows us to generate new data under the alternative hypothesis, which helps us identify when the data come from different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "why_shuffle = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Battery Life üîãüéß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You and your friend are studying together for a final. Since both of you focus better when listening to music, you  challenge yourselves to study uninterrupted until each of your earbuds run out of battery. You own a pair of _Apple AirPods_ (i.e., AirPods) and your friend owns a pair of _Samsung Galaxy Buds Pro_ (i.e., Galaxy Buds). You both put on your earbuds and get to work.\n",
    "\n",
    "At the end of the study session, you find that your AirPods, which were fully charged at the start, lasted 4 hours and 18 minutes, while your friend's Galaxy Buds, also fully charged at the start, lasted 4 hours and 41 minutes. Intrigued by the noticeable difference in battery life between the two earbuds, you decide to investigate further. You make a post on Reddit asking people who have AirPods or Galaxy Buds to record how long their earbuds last on a single charge. You're overwhelmed by the amazing response and receive 80 different comments in total from other people, 40 from people with AirPods and 40 from people with Galaxy Buds.\n",
    "\n",
    "Let's look at all the data that you crowdsourced. Each entry in the `'BatteryLife'` column represents the amount of time that a pair of earbuds lasted on a full charge, in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_life_data = bpd.read_csv('data/earbuds.csv')\n",
    "battery_life_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Now let's address the question: how does the average battery life of Galaxy Buds compare to that of AirPods? Create a DataFrame called `galaxy` that contains only the battery life data for Galaxy Buds, and set `galaxy_mean` to the mean battery life of Galaxy Buds. Similarly, create a DataFrame `airpods` for AirPods and compute `airpods_mean`. Finally, set `observed_diff_mean`, to the difference in mean battery life of Galaxy Buds and AirPods in our sample, computed as follows.\n",
    "\n",
    "$$\\text{difference} = \\text{mean battery life of Galaxy Buds} - \\text{mean battery life of AirPods}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy = ...\n",
    "airpods = ...\n",
    "galaxy_mean = ...\n",
    "airpods_mean = ...\n",
    "observed_diff_mean = ...\n",
    "observed_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you answered Question 4.1 correctly, you should have noticed a difference in the average battery life between Galaxy Buds and AirPods. But remember, we are only analyzing samples of size 40 for each brand. Would we observe such a difference in battery life if we had access to the entire population ‚Äì that is, all units ever produced by both brands ‚Äì or is it possible that this difference is merely a result of the specific samples we happened to collect? Let's do a **hypothesis test** to find out. We'll state our hypotheses as follows:\n",
    "\n",
    "- **Null Hypothesis**: The average battery life of Galaxy Buds is equal to that of AirPods. In other words, the difference in average battery life between the two brands equals 0 minutes.\n",
    "\n",
    "- **Alternative Hypothesis**: The average battery life of Galaxy Buds is not equal to that of AirPods. Hence, the difference in average battery life between the two brands is not 0 minutes.\n",
    "\n",
    "\n",
    "Since we are able to frame our hypothesis test as a question of whether a certain population parameter ‚Äì the difference in average battery life between Galaxy Buds and AirPods ‚Äì is equal to a specific value, we can **test our hypotheses by constructing a confidence interval** for this parameter. For a refresher on this method, refer to [CIT 13.4](https://inferentialthinking.com/chapters/13/4/Using_Confidence_Intervals.html) or the human body temperature example from [Lecture 21](https://dsc10.com/resources/lectures/lec21/lec21.html).\n",
    "\n",
    "***Note:*** We are **not** conducting a permutation test here, although that would also be a valid approach to test these hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Compute 1000 **bootstrapped estimates** for the difference in average battery life between Galaxy Buds and AirPods. As in Question 4.1, calculate the difference as Galaxy Buds minus AirPods. Store your 1000 estimates in the `difference_means` array.\n",
    "\n",
    "You should generate your Galaxy Buds resamples by sampling from `galaxy`, and your AirPods resamples by sampling from `airpods`. Do not use the combined dataset `battery_life_data` for this task, otherwise you might not wind up with 40 of each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_means = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "difference_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize your estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(BootstrappedDifferenceMeans = difference_means).plot(kind = 'hist', density=True, ec='w', bins=20, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Compute a 95% confidence interval for the difference in mean battery life of AirPods and Galaxy Buds (as before, in the order Galaxy Buds minus AirPods). Assign the left and right endpoints of this confidence interval to `left_endpoint` and `right_endpoint` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = ...\n",
    "right_endpoint = ...\n",
    "\n",
    "print('Bootstrapped 95% confidence interval for the mean difference in battery life of AirPods and Galaxy Buds:\\n [{:f}, {:f}]'.format(left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Based on the confidence interval you've created, would you reject the null hypothesis at the 0.05 significance level? Set `reject_null` to True if you would reject the null hypothesis, and False if you would not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_null = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5.** What if all the people who responded to your original Reddit post had provided their battery lives in hours instead of minutes? Would your hypothesis test still come to the same conclusion either way? Set `same_conclusion` to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! üèÅ\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 6 ‚Äì the final homework of the quarter! üéâ\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "1. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "1. Run the cell below to run all tests, and make sure that they all pass.\n",
    "1. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "1. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "1. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
